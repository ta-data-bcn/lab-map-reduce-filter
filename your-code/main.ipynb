{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before your start:\n",
    "- Read the README.md file\n",
    "- Comment as much as you can and use the resources in the README.md file\n",
    "- Happy learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import reduce from functools, numpy and pandas\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Mapping\n",
    "\n",
    "#### We will use the map function to clean up words in a book.\n",
    "\n",
    "In the following cell, we will read a text file containing the book The Prophet by Khalil Gibran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code:\n",
    "\n",
    "location = '../data/58585-0.txt'\n",
    "with open(location, 'r', encoding=\"utf8\") as f:\n",
    "    prophet = f.read().split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's remove the first 568 words since they contain information about the book but are not part of the book itself. \n",
    "\n",
    "Do this by removing from `prophet` elements 0 through 567 of the list (you can also do this by keeping elements 568 through the last element)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "prophet = prophet[568:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look through the words, you will find that many words have a reference attached to them. For example, let's look at words 1 through 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROPHET\\n\\n|Almustafa,',\n",
       " 'the{7}',\n",
       " 'chosen',\n",
       " 'and',\n",
       " 'the\\nbeloved,',\n",
       " 'who',\n",
       " 'was',\n",
       " 'a',\n",
       " 'dawn']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "prophet[0:9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The next step is to create a function that will remove references. \n",
    "\n",
    "We will do this by splitting the string on the `{` character and keeping only the part before this character. Write your function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reference(x):\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: The string with references removed\n",
    "    \n",
    "    Example:\n",
    "    Input: 'the{7}'\n",
    "    Output: 'the'\n",
    "    '''\n",
    "    \n",
    "    # your code here\n",
    "    pattern = '{.*}'\n",
    "    return re.sub(pattern, '', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our function, use the `map()` function to apply this function to our book, The Prophet. Return the resulting list to a new list called `prophet_reference`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "prophet_reference = list(map(reference, prophet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing you may have noticed is that some words contain a line break. Let's write a function to split those words. Our function will return the string split on the character `\\n`. Write your function in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_break(x):\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: A list of strings split on the line break (\\n) character\n",
    "        \n",
    "    Example:\n",
    "    Input: 'the\\nbeloved'\n",
    "    Output: ['the', 'beloved']\n",
    "    '''\n",
    "    \n",
    "    # your code here\n",
    "    return x.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the `line_break` function to the `prophet_reference` list. Name the new list `prophet_line`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "prophet_line = list(map(line_break, prophet_reference))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the elements of `prophet_line`, you will see that the function returned lists and not strings. Our list is now a list of lists. Flatten the list using list comprehension. Assign this new list to `prophet_flat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_flat = [y for x in prophet_line for y in x]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Filtering\n",
    "\n",
    "When printing out a few words from the book, we see that there are words that we may not want to keep if we choose to analyze the corpus of text. Below is a list of words that we would like to get rid of. Create a function that will return false if it contains a word from the list of words specified and true otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_filter(x):\n",
    "    '''\n",
    "    Input: A string\n",
    "    Output: True if the word is not in the specified list \n",
    "    and False if the word is in the list.\n",
    "        \n",
    "    Example:\n",
    "    word list = ['and', 'the']\n",
    "    Input: 'and'\n",
    "    Output: False\n",
    "    \n",
    "    Input: 'John'\n",
    "    Output: True\n",
    "    '''\n",
    "    \n",
    "    word_list = ['and', 'the', 'a', 'an']\n",
    "    \n",
    "    # your code here\n",
    "    if x in word_list:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `filter()` function to filter out the words speficied in the `word_filter()` function. Store the filtered list in the variable `prophet_filter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_filter = list(filter(word_filter, prophet_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PROPHET',\n",
       " '|Almustafa,',\n",
       " 'chosen',\n",
       " 'beloved,',\n",
       " 'who',\n",
       " 'was',\n",
       " 'dawn',\n",
       " 'unto',\n",
       " 'his',\n",
       " 'own',\n",
       " 'day,',\n",
       " 'had',\n",
       " 'waited',\n",
       " 'twelve',\n",
       " 'years',\n",
       " 'in',\n",
       " 'city',\n",
       " 'of',\n",
       " 'Orphalese',\n",
       " 'for',\n",
       " 'his',\n",
       " 'ship',\n",
       " 'that',\n",
       " 'was',\n",
       " 'to',\n",
       " 'return',\n",
       " 'bear',\n",
       " 'him',\n",
       " 'back',\n",
       " 'to',\n",
       " 'isle',\n",
       " 'of',\n",
       " 'his',\n",
       " 'birth.',\n",
       " 'And',\n",
       " 'in',\n",
       " 'twelfth',\n",
       " 'year,',\n",
       " 'on',\n",
       " 'seventh',\n",
       " 'day',\n",
       " 'of',\n",
       " 'Ielool,',\n",
       " 'month',\n",
       " 'of',\n",
       " 'reaping,',\n",
       " 'he',\n",
       " 'climbed',\n",
       " 'hill',\n",
       " 'without',\n",
       " 'city',\n",
       " 'walls',\n",
       " 'looked',\n",
       " 'seaward;',\n",
       " 'he',\n",
       " 'beheld',\n",
       " 'his',\n",
       " 'ship',\n",
       " 'coming',\n",
       " 'with',\n",
       " 'mist.',\n",
       " 'Then',\n",
       " 'gates',\n",
       " 'of',\n",
       " 'his',\n",
       " 'heart',\n",
       " 'were',\n",
       " 'flung',\n",
       " 'open,',\n",
       " 'his',\n",
       " 'joy',\n",
       " 'flew',\n",
       " 'far',\n",
       " 'over',\n",
       " 'sea.',\n",
       " 'And',\n",
       " 'he',\n",
       " 'closed',\n",
       " 'his',\n",
       " 'eyes',\n",
       " 'prayed',\n",
       " 'in',\n",
       " 'silences',\n",
       " 'of',\n",
       " 'his',\n",
       " 'soul.',\n",
       " '*****',\n",
       " 'But',\n",
       " 'as',\n",
       " 'he',\n",
       " 'descended',\n",
       " 'hill,',\n",
       " 'sadness',\n",
       " 'came',\n",
       " 'upon',\n",
       " 'him,',\n",
       " 'he',\n",
       " 'thought',\n",
       " 'in',\n",
       " 'his',\n",
       " 'heart:',\n",
       " 'How',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'go',\n",
       " 'in',\n",
       " 'peace',\n",
       " 'without',\n",
       " 'sorrow?',\n",
       " 'Nay,',\n",
       " 'not',\n",
       " 'without',\n",
       " 'wound',\n",
       " 'in',\n",
       " 'spirit',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'leave',\n",
       " 'this',\n",
       " 'city.',\n",
       " 'Long',\n",
       " 'were',\n",
       " 'days',\n",
       " 'of',\n",
       " 'pain',\n",
       " 'I',\n",
       " 'have',\n",
       " 'spent',\n",
       " 'within',\n",
       " 'its',\n",
       " 'walls,',\n",
       " 'long',\n",
       " 'were',\n",
       " 'nights',\n",
       " 'of',\n",
       " 'aloneness;',\n",
       " 'who',\n",
       " 'can',\n",
       " 'depart',\n",
       " 'from',\n",
       " 'his',\n",
       " 'pain',\n",
       " 'his',\n",
       " 'aloneness',\n",
       " 'without',\n",
       " 'regret?',\n",
       " 'Too',\n",
       " 'many',\n",
       " 'fragments',\n",
       " 'of',\n",
       " 'spirit',\n",
       " 'have',\n",
       " 'I',\n",
       " 'scattered',\n",
       " 'in',\n",
       " 'these',\n",
       " 'streets,',\n",
       " 'too',\n",
       " 'many',\n",
       " 'are',\n",
       " 'children',\n",
       " 'of',\n",
       " 'my',\n",
       " 'longing',\n",
       " 'that',\n",
       " 'walk',\n",
       " 'naked',\n",
       " 'among',\n",
       " 'these',\n",
       " 'hills,',\n",
       " 'I',\n",
       " 'cannot',\n",
       " 'withdraw',\n",
       " 'from',\n",
       " 'them',\n",
       " 'without',\n",
       " 'burden',\n",
       " 'ache.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'not',\n",
       " 'garment',\n",
       " 'I',\n",
       " 'cast',\n",
       " 'off',\n",
       " 'this',\n",
       " 'day,',\n",
       " 'but',\n",
       " 'skin',\n",
       " 'that',\n",
       " 'I',\n",
       " 'tear',\n",
       " 'with',\n",
       " 'my',\n",
       " 'own',\n",
       " 'hands.',\n",
       " 'Nor',\n",
       " 'is',\n",
       " 'it',\n",
       " 'thought',\n",
       " 'I',\n",
       " 'leave',\n",
       " 'behind',\n",
       " 'me,',\n",
       " 'but',\n",
       " 'heart',\n",
       " 'made',\n",
       " 'sweet',\n",
       " 'with',\n",
       " 'hunger',\n",
       " 'with',\n",
       " 'thirst.',\n",
       " '*****',\n",
       " 'Yet',\n",
       " 'I',\n",
       " 'cannot',\n",
       " 'tarry',\n",
       " 'longer.',\n",
       " 'The',\n",
       " 'sea',\n",
       " 'that',\n",
       " 'calls',\n",
       " 'all',\n",
       " 'things',\n",
       " 'unto',\n",
       " 'her',\n",
       " 'calls',\n",
       " 'me,',\n",
       " 'I',\n",
       " 'must',\n",
       " 'embark.',\n",
       " 'For',\n",
       " 'to',\n",
       " 'stay,',\n",
       " 'though',\n",
       " 'hours',\n",
       " 'burn',\n",
       " 'in',\n",
       " 'night,',\n",
       " 'is',\n",
       " 'to',\n",
       " 'freeze',\n",
       " 'crystallize',\n",
       " 'be',\n",
       " 'bound',\n",
       " 'in',\n",
       " 'mould.',\n",
       " 'Fain',\n",
       " 'would',\n",
       " 'I',\n",
       " 'take',\n",
       " 'with',\n",
       " 'me',\n",
       " 'all',\n",
       " 'that',\n",
       " 'is',\n",
       " 'here.',\n",
       " 'But',\n",
       " 'how',\n",
       " 'shall',\n",
       " 'I?',\n",
       " 'A',\n",
       " 'voice',\n",
       " 'cannot',\n",
       " 'carry',\n",
       " 'tongue',\n",
       " 'lips',\n",
       " 'that',\n",
       " 'gave',\n",
       " 'it',\n",
       " 'wings.',\n",
       " 'Alone',\n",
       " 'must',\n",
       " 'it',\n",
       " 'seek',\n",
       " 'ether.',\n",
       " 'And',\n",
       " 'alone',\n",
       " 'without',\n",
       " 'his',\n",
       " 'nest',\n",
       " 'shall',\n",
       " 'eagle',\n",
       " 'fly',\n",
       " 'across',\n",
       " 'sun.',\n",
       " '*****',\n",
       " 'Now',\n",
       " 'when',\n",
       " 'he',\n",
       " 'reached',\n",
       " 'foot',\n",
       " 'of',\n",
       " 'hill,',\n",
       " 'he',\n",
       " 'turned',\n",
       " 'again',\n",
       " 'towards',\n",
       " 'sea,',\n",
       " 'he',\n",
       " 'saw',\n",
       " 'his',\n",
       " 'ship',\n",
       " 'approaching',\n",
       " 'harbour,',\n",
       " 'upon',\n",
       " 'her',\n",
       " 'prow',\n",
       " 'mariners,',\n",
       " 'men',\n",
       " 'of',\n",
       " 'his',\n",
       " 'own',\n",
       " 'land.',\n",
       " 'And',\n",
       " 'his',\n",
       " 'soul',\n",
       " 'cried',\n",
       " 'out',\n",
       " 'to',\n",
       " 'them,',\n",
       " 'he',\n",
       " 'said:',\n",
       " 'Sons',\n",
       " 'of',\n",
       " 'my',\n",
       " 'ancient',\n",
       " 'mother,',\n",
       " 'you',\n",
       " 'riders',\n",
       " 'of',\n",
       " 'tides,',\n",
       " 'How',\n",
       " 'often',\n",
       " 'have',\n",
       " 'you',\n",
       " 'sailed',\n",
       " 'in',\n",
       " 'my',\n",
       " 'dreams.',\n",
       " 'And',\n",
       " 'now',\n",
       " 'you',\n",
       " 'come',\n",
       " 'in',\n",
       " 'my',\n",
       " 'awakening,',\n",
       " 'which',\n",
       " 'is',\n",
       " 'my',\n",
       " 'deeper',\n",
       " 'dream.',\n",
       " 'Ready',\n",
       " 'am',\n",
       " 'I',\n",
       " 'to',\n",
       " 'go,',\n",
       " 'my',\n",
       " 'eagerness',\n",
       " 'with',\n",
       " 'sails',\n",
       " 'full',\n",
       " 'set',\n",
       " 'awaits',\n",
       " 'wind.',\n",
       " 'Only',\n",
       " 'another',\n",
       " 'breath',\n",
       " 'will',\n",
       " 'I',\n",
       " 'breathe',\n",
       " 'in',\n",
       " 'this',\n",
       " 'still',\n",
       " 'air,',\n",
       " 'only',\n",
       " 'another',\n",
       " 'loving',\n",
       " 'look',\n",
       " 'cast',\n",
       " 'backward,',\n",
       " 'And',\n",
       " 'then',\n",
       " 'I',\n",
       " 'shall',\n",
       " 'stand',\n",
       " 'among',\n",
       " 'you,',\n",
       " 'seafarer',\n",
       " 'among',\n",
       " 'seafarers.',\n",
       " 'And',\n",
       " 'you,',\n",
       " 'vast',\n",
       " 'sea,',\n",
       " 'sleepless',\n",
       " 'mother,',\n",
       " 'Who',\n",
       " 'alone',\n",
       " 'are',\n",
       " 'peace',\n",
       " 'freedom',\n",
       " 'to',\n",
       " 'river',\n",
       " 'stream,',\n",
       " 'Only',\n",
       " 'another',\n",
       " 'winding',\n",
       " 'will',\n",
       " 'this',\n",
       " 'stream',\n",
       " 'make,',\n",
       " 'only',\n",
       " 'another',\n",
       " 'murmur',\n",
       " 'in',\n",
       " 'this',\n",
       " 'glade,',\n",
       " 'And',\n",
       " 'then',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'come',\n",
       " 'to',\n",
       " 'you,',\n",
       " 'boundless',\n",
       " 'drop',\n",
       " 'to',\n",
       " 'boundless',\n",
       " 'ocean.',\n",
       " '*****',\n",
       " 'And',\n",
       " 'as',\n",
       " 'he',\n",
       " 'walked',\n",
       " 'he',\n",
       " 'saw',\n",
       " 'from',\n",
       " 'afar',\n",
       " 'men',\n",
       " 'women',\n",
       " 'leaving',\n",
       " 'their',\n",
       " 'fields',\n",
       " 'their',\n",
       " 'vineyards',\n",
       " 'hastening',\n",
       " 'towards',\n",
       " 'city',\n",
       " 'gates.',\n",
       " 'And',\n",
       " 'he',\n",
       " 'heard',\n",
       " 'their',\n",
       " 'voices',\n",
       " 'calling',\n",
       " 'his',\n",
       " 'name,',\n",
       " 'shouting',\n",
       " 'from',\n",
       " 'field',\n",
       " 'to',\n",
       " 'field',\n",
       " 'telling',\n",
       " 'one',\n",
       " 'another',\n",
       " 'of',\n",
       " 'coming',\n",
       " 'of',\n",
       " 'his',\n",
       " 'ship.',\n",
       " 'And',\n",
       " 'he',\n",
       " 'said',\n",
       " 'to',\n",
       " 'himself:',\n",
       " 'Shall',\n",
       " 'day',\n",
       " 'of',\n",
       " 'parting',\n",
       " 'be',\n",
       " 'day',\n",
       " 'of',\n",
       " 'gathering?',\n",
       " 'And',\n",
       " 'shall',\n",
       " 'it',\n",
       " 'be',\n",
       " 'said',\n",
       " 'that',\n",
       " 'my',\n",
       " 'eve',\n",
       " 'was',\n",
       " 'in',\n",
       " 'truth',\n",
       " 'my',\n",
       " 'dawn?',\n",
       " 'And',\n",
       " 'what',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'give',\n",
       " 'unto',\n",
       " 'him',\n",
       " 'who',\n",
       " 'has',\n",
       " 'left',\n",
       " 'his',\n",
       " 'plough',\n",
       " 'in',\n",
       " 'midfurrow,',\n",
       " 'or',\n",
       " 'to',\n",
       " 'him',\n",
       " 'who',\n",
       " 'has',\n",
       " 'stopped',\n",
       " 'wheel',\n",
       " 'of',\n",
       " 'his',\n",
       " 'winepress?',\n",
       " 'Shall',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'become',\n",
       " 'tree',\n",
       " 'heavy-laden',\n",
       " 'with',\n",
       " 'fruit',\n",
       " 'that',\n",
       " 'I',\n",
       " 'may',\n",
       " 'gather',\n",
       " 'give',\n",
       " 'unto',\n",
       " 'them?',\n",
       " 'And',\n",
       " 'shall',\n",
       " 'my',\n",
       " 'desires',\n",
       " 'flow',\n",
       " 'like',\n",
       " 'fountain',\n",
       " 'that',\n",
       " 'I',\n",
       " 'may',\n",
       " 'fill',\n",
       " 'their',\n",
       " 'cups?',\n",
       " 'Am',\n",
       " 'I',\n",
       " 'harp',\n",
       " 'that',\n",
       " 'hand',\n",
       " 'of',\n",
       " 'mighty',\n",
       " 'may',\n",
       " 'touch',\n",
       " 'me,',\n",
       " 'or',\n",
       " 'flute',\n",
       " 'that',\n",
       " 'his',\n",
       " 'breath',\n",
       " 'may',\n",
       " 'pass',\n",
       " 'through',\n",
       " 'me?',\n",
       " 'A',\n",
       " 'seeker',\n",
       " 'of',\n",
       " 'silences',\n",
       " 'am',\n",
       " 'I,',\n",
       " 'what',\n",
       " 'treasure',\n",
       " 'have',\n",
       " 'I',\n",
       " 'found',\n",
       " 'in',\n",
       " 'silences',\n",
       " 'that',\n",
       " 'I',\n",
       " 'may',\n",
       " 'dispense',\n",
       " 'with',\n",
       " 'confidence?',\n",
       " 'If',\n",
       " 'this',\n",
       " 'is',\n",
       " 'my',\n",
       " 'day',\n",
       " 'of',\n",
       " 'harvest,',\n",
       " 'in',\n",
       " 'what',\n",
       " 'fields',\n",
       " 'have',\n",
       " 'I',\n",
       " 'sowed',\n",
       " 'seed,',\n",
       " 'in',\n",
       " 'what',\n",
       " 'unremembered',\n",
       " 'seasons?',\n",
       " 'If',\n",
       " 'this',\n",
       " 'indeed',\n",
       " 'be',\n",
       " 'hour',\n",
       " 'in',\n",
       " 'which',\n",
       " 'I',\n",
       " 'lift',\n",
       " 'up',\n",
       " 'my',\n",
       " 'lantern,',\n",
       " 'it',\n",
       " 'is',\n",
       " 'not',\n",
       " 'my',\n",
       " 'flame',\n",
       " 'that',\n",
       " 'shall',\n",
       " 'burn',\n",
       " 'therein.',\n",
       " 'Empty',\n",
       " 'dark',\n",
       " 'shall',\n",
       " 'I',\n",
       " 'raise',\n",
       " 'my',\n",
       " 'lantern,',\n",
       " 'And',\n",
       " 'guardian',\n",
       " 'of',\n",
       " 'night',\n",
       " 'shall',\n",
       " 'fill',\n",
       " 'it',\n",
       " 'with',\n",
       " 'oil',\n",
       " 'he',\n",
       " 'shall',\n",
       " 'light',\n",
       " 'it',\n",
       " 'also.',\n",
       " '*****',\n",
       " 'These',\n",
       " 'things',\n",
       " 'he',\n",
       " 'said',\n",
       " 'in',\n",
       " 'words.',\n",
       " 'But',\n",
       " 'much',\n",
       " 'in',\n",
       " 'his',\n",
       " 'heart',\n",
       " 'remained',\n",
       " 'unsaid.',\n",
       " 'For',\n",
       " 'he',\n",
       " 'himself',\n",
       " 'could',\n",
       " 'not',\n",
       " 'speak',\n",
       " 'his',\n",
       " 'deeper',\n",
       " 'secret.',\n",
       " '*****',\n",
       " '[Illustration:',\n",
       " '0020]',\n",
       " 'And',\n",
       " 'when',\n",
       " 'he',\n",
       " 'entered',\n",
       " 'into',\n",
       " 'city',\n",
       " 'all',\n",
       " 'people',\n",
       " 'came',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'him,',\n",
       " 'they',\n",
       " 'were',\n",
       " 'crying',\n",
       " 'out',\n",
       " 'to',\n",
       " 'him',\n",
       " 'as',\n",
       " 'with',\n",
       " 'one',\n",
       " 'voice.',\n",
       " 'And',\n",
       " 'elders',\n",
       " 'of',\n",
       " 'city',\n",
       " 'stood',\n",
       " 'forth',\n",
       " 'said:',\n",
       " 'Go',\n",
       " 'not',\n",
       " 'yet',\n",
       " 'away',\n",
       " 'from',\n",
       " 'us.',\n",
       " 'A',\n",
       " 'noontide',\n",
       " 'have',\n",
       " 'you',\n",
       " 'been',\n",
       " 'in',\n",
       " 'our',\n",
       " 'twilight,',\n",
       " 'your',\n",
       " 'youth',\n",
       " 'has',\n",
       " 'given',\n",
       " 'us',\n",
       " 'dreams',\n",
       " 'to',\n",
       " 'dream.',\n",
       " 'No',\n",
       " 'stranger',\n",
       " 'are',\n",
       " 'you',\n",
       " 'among',\n",
       " 'us,',\n",
       " 'nor',\n",
       " 'guest,',\n",
       " 'but',\n",
       " 'our',\n",
       " 'son',\n",
       " 'our',\n",
       " 'dearly',\n",
       " 'beloved.',\n",
       " 'Suffer',\n",
       " 'not',\n",
       " 'yet',\n",
       " 'our',\n",
       " 'eyes',\n",
       " 'to',\n",
       " 'hunger',\n",
       " 'for',\n",
       " 'your',\n",
       " 'face.',\n",
       " '*****',\n",
       " 'And',\n",
       " 'priests',\n",
       " 'priestesses',\n",
       " 'said',\n",
       " 'unto',\n",
       " 'him:',\n",
       " 'Let',\n",
       " 'not',\n",
       " 'waves',\n",
       " 'of',\n",
       " 'sea',\n",
       " 'separate',\n",
       " 'us',\n",
       " 'now,',\n",
       " 'years',\n",
       " 'you',\n",
       " 'have',\n",
       " 'spent',\n",
       " 'in',\n",
       " 'our',\n",
       " 'midst',\n",
       " 'become',\n",
       " 'memory.',\n",
       " 'You',\n",
       " 'have',\n",
       " 'walked',\n",
       " 'among',\n",
       " 'us',\n",
       " 'spirit,',\n",
       " 'your',\n",
       " 'shadow',\n",
       " 'has',\n",
       " 'been',\n",
       " 'light',\n",
       " 'upon',\n",
       " 'our',\n",
       " 'faces.',\n",
       " 'Much',\n",
       " 'have',\n",
       " 'we',\n",
       " 'loved',\n",
       " 'you.',\n",
       " 'But',\n",
       " 'speechless',\n",
       " 'was',\n",
       " 'our',\n",
       " 'love,',\n",
       " 'with',\n",
       " 'veils',\n",
       " 'has',\n",
       " 'it',\n",
       " 'been',\n",
       " 'veiled.',\n",
       " 'Yet',\n",
       " 'now',\n",
       " 'it',\n",
       " 'cries',\n",
       " 'aloud',\n",
       " 'unto',\n",
       " 'you,',\n",
       " 'would',\n",
       " 'stand',\n",
       " 'revealed',\n",
       " 'before',\n",
       " 'you.',\n",
       " 'And',\n",
       " 'ever',\n",
       " 'has',\n",
       " 'it',\n",
       " 'been',\n",
       " 'that',\n",
       " 'love',\n",
       " 'knows',\n",
       " 'not',\n",
       " 'its',\n",
       " 'own',\n",
       " 'depth',\n",
       " 'until',\n",
       " 'hour',\n",
       " 'of',\n",
       " 'separation.',\n",
       " '*****',\n",
       " 'And',\n",
       " 'others',\n",
       " 'came',\n",
       " 'also',\n",
       " 'entreated',\n",
       " 'him.',\n",
       " 'But',\n",
       " 'he',\n",
       " 'answered',\n",
       " 'them',\n",
       " 'not.',\n",
       " 'He',\n",
       " 'only',\n",
       " 'bent',\n",
       " 'his',\n",
       " 'head;',\n",
       " 'those',\n",
       " 'who',\n",
       " 'stood',\n",
       " 'near',\n",
       " 'saw',\n",
       " 'his',\n",
       " 'tears',\n",
       " 'falling',\n",
       " 'upon',\n",
       " 'his',\n",
       " 'breast.',\n",
       " 'And',\n",
       " 'he',\n",
       " 'people',\n",
       " 'proceeded',\n",
       " 'towards',\n",
       " 'great',\n",
       " 'square',\n",
       " 'before',\n",
       " 'temple.',\n",
       " 'And',\n",
       " 'there',\n",
       " 'came',\n",
       " 'out',\n",
       " 'of',\n",
       " 'sanctuary',\n",
       " 'woman',\n",
       " 'whose',\n",
       " 'name',\n",
       " 'was',\n",
       " 'Almitra.',\n",
       " 'And',\n",
       " 'she',\n",
       " 'was',\n",
       " 'seeress.',\n",
       " 'And',\n",
       " 'he',\n",
       " 'looked',\n",
       " 'upon',\n",
       " 'her',\n",
       " 'with',\n",
       " 'exceeding',\n",
       " 'tenderness,',\n",
       " 'for',\n",
       " 'it',\n",
       " 'was',\n",
       " 'she',\n",
       " 'who',\n",
       " 'had',\n",
       " 'first',\n",
       " 'sought',\n",
       " 'believed',\n",
       " 'in',\n",
       " 'him',\n",
       " 'when',\n",
       " 'he',\n",
       " 'had',\n",
       " 'been',\n",
       " 'but',\n",
       " 'day',\n",
       " 'in',\n",
       " 'their',\n",
       " 'city.',\n",
       " 'And',\n",
       " 'she',\n",
       " 'hailed',\n",
       " 'him,',\n",
       " 'saying:',\n",
       " 'Prophet',\n",
       " 'of',\n",
       " 'God,',\n",
       " 'in',\n",
       " 'quest',\n",
       " 'of',\n",
       " 'uttermost,',\n",
       " 'long',\n",
       " 'have',\n",
       " 'you',\n",
       " 'searched',\n",
       " 'distances',\n",
       " 'for',\n",
       " 'your',\n",
       " 'ship.',\n",
       " 'And',\n",
       " 'now',\n",
       " 'your',\n",
       " 'ship',\n",
       " 'has',\n",
       " 'come,',\n",
       " 'you',\n",
       " 'must',\n",
       " 'needs',\n",
       " 'go.',\n",
       " 'Deep',\n",
       " 'is',\n",
       " 'your',\n",
       " 'longing',\n",
       " 'for',\n",
       " 'land',\n",
       " 'of',\n",
       " 'your',\n",
       " 'memories',\n",
       " 'dwelling',\n",
       " 'place',\n",
       " 'of',\n",
       " 'your',\n",
       " 'greater',\n",
       " 'desires;',\n",
       " 'our',\n",
       " 'love',\n",
       " 'would',\n",
       " 'not',\n",
       " 'bind',\n",
       " 'you',\n",
       " 'nor',\n",
       " 'our',\n",
       " 'needs',\n",
       " 'hold',\n",
       " 'you.',\n",
       " 'Yet',\n",
       " 'this',\n",
       " 'we',\n",
       " 'ask',\n",
       " 'ere',\n",
       " 'you',\n",
       " 'leave',\n",
       " 'us,',\n",
       " 'that',\n",
       " 'you',\n",
       " 'speak',\n",
       " 'to',\n",
       " 'us',\n",
       " 'give',\n",
       " 'us',\n",
       " 'of',\n",
       " 'your',\n",
       " 'truth.',\n",
       " 'And',\n",
       " 'we',\n",
       " 'will',\n",
       " 'give',\n",
       " 'it',\n",
       " 'unto',\n",
       " 'our',\n",
       " 'children,',\n",
       " 'they',\n",
       " 'unto',\n",
       " 'their',\n",
       " 'children,',\n",
       " 'it',\n",
       " 'shall',\n",
       " 'not',\n",
       " 'perish.',\n",
       " ...]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prophet_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge\n",
    "\n",
    "Rewrite the `word_filter` function above to not be case sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_filter_case(x):\n",
    "   \n",
    "    word_list = ['and', 'the', 'a', 'an']\n",
    "    \n",
    "    # your code here\n",
    "    if x.lower() in word_list:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Reducing\n",
    "\n",
    "#### Now that we have significantly cleaned up our text corpus, let's use the `reduce()` function to put the words back together into one long string separated by spaces. \n",
    "\n",
    "We will start by writing a function that takes two strings and concatenates them together with a space between the two strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_space(a, b):\n",
    "    '''\n",
    "    Input:Two strings\n",
    "    Output: A single string separated by a space\n",
    "        \n",
    "    Example:\n",
    "    Input: 'John', 'Smith'\n",
    "    Output: 'John Smith'\n",
    "    '''\n",
    "    \n",
    "    # your code here\n",
    "    return f'{a} {b}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function above to reduce the text corpus in the list `prophet_filter` into a single string. Assign this new string to the variable `prophet_string`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "prophet_string = reduce(concat_space, prophet_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 4 - Applying Functions to DataFrames\n",
    "\n",
    "#### Our next step is to use the apply function to a dataframe and transform all cells.\n",
    "\n",
    "To do this, we will connect to Ironhack's database and retrieve the data from the *pollution* database. Select the *beijing_pollution* table and retrieve its data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "df = pd.read_csv('pollution.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data using the `head()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>12.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  year  month  day  hour  pm2.5  DEWP  TEMP    PRES cbwd    Iws  Is  Ir\n",
       "0   1  2010      1    1     0    NaN   -21 -11.0  1021.0   NW   1.79   0   0\n",
       "1   2  2010      1    1     1    NaN   -21 -12.0  1020.0   NW   4.92   0   0\n",
       "2   3  2010      1    1     2    NaN   -21 -11.0  1019.0   NW   6.71   0   0\n",
       "3   4  2010      1    1     3    NaN   -21 -14.0  1019.0   NW   9.84   0   0\n",
       "4   5  2010      1    1     4    NaN   -20 -12.0  1018.0   NW  12.97   0   0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create a function that divides a cell by 24 to produce an hourly figure. Write the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourly(x):\n",
    "    '''\n",
    "    Input: A numerical value\n",
    "    Output: The value divided by 24\n",
    "        \n",
    "    Example:\n",
    "    Input: 48\n",
    "    Output: 2.0\n",
    "    '''\n",
    "    \n",
    "    # your code here\n",
    "    return x/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply this function to the columns `Iws`, `Is`, and `Ir`. Store this new dataframe in the variable `pm25_hourly`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "pm25_hourly = df[['Iws', 'Is', 'Ir']].apply(hourly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.074583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.205000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.540417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.670833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.801250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.875833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.006250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.136667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.304167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.434583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.565000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.695417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.825833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.037083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.074583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.111667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.074583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.074583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.037083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.074583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.111667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.037083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.074583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.111667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.148750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.223333</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.260417</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.297500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43794</th>\n",
       "      <td>0.149167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43795</th>\n",
       "      <td>0.242083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43796</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43797</th>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43798</th>\n",
       "      <td>1.322083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43799</th>\n",
       "      <td>1.620000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43800</th>\n",
       "      <td>2.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43801</th>\n",
       "      <td>2.569583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43802</th>\n",
       "      <td>2.942083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43803</th>\n",
       "      <td>3.407917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43804</th>\n",
       "      <td>3.947917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43805</th>\n",
       "      <td>4.581250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43806</th>\n",
       "      <td>5.419583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43807</th>\n",
       "      <td>5.959583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43808</th>\n",
       "      <td>6.257500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43809</th>\n",
       "      <td>6.499583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43810</th>\n",
       "      <td>6.797500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43811</th>\n",
       "      <td>7.095417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43812</th>\n",
       "      <td>7.393333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43813</th>\n",
       "      <td>7.765833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43814</th>\n",
       "      <td>8.175417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43815</th>\n",
       "      <td>8.547917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43816</th>\n",
       "      <td>8.920417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43817</th>\n",
       "      <td>9.218333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43818</th>\n",
       "      <td>9.423333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43819</th>\n",
       "      <td>9.665417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43820</th>\n",
       "      <td>9.907500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43821</th>\n",
       "      <td>10.112500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43822</th>\n",
       "      <td>10.280000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43823</th>\n",
       "      <td>10.410417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43824 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Iws        Is   Ir\n",
       "0       0.074583  0.000000  0.0\n",
       "1       0.205000  0.000000  0.0\n",
       "2       0.279583  0.000000  0.0\n",
       "3       0.410000  0.000000  0.0\n",
       "4       0.540417  0.000000  0.0\n",
       "5       0.670833  0.000000  0.0\n",
       "6       0.801250  0.000000  0.0\n",
       "7       0.875833  0.000000  0.0\n",
       "8       1.006250  0.000000  0.0\n",
       "9       1.136667  0.000000  0.0\n",
       "10      1.304167  0.000000  0.0\n",
       "11      1.434583  0.000000  0.0\n",
       "12      1.565000  0.000000  0.0\n",
       "13      1.695417  0.000000  0.0\n",
       "14      1.825833  0.000000  0.0\n",
       "15      0.037083  0.000000  0.0\n",
       "16      0.074583  0.000000  0.0\n",
       "17      0.111667  0.000000  0.0\n",
       "18      0.074583  0.000000  0.0\n",
       "19      0.074583  0.000000  0.0\n",
       "20      0.037083  0.000000  0.0\n",
       "21      0.074583  0.000000  0.0\n",
       "22      0.111667  0.000000  0.0\n",
       "23      0.037083  0.000000  0.0\n",
       "24      0.074583  0.000000  0.0\n",
       "25      0.111667  0.000000  0.0\n",
       "26      0.148750  0.000000  0.0\n",
       "27      0.223333  0.041667  0.0\n",
       "28      0.260417  0.083333  0.0\n",
       "29      0.297500  0.125000  0.0\n",
       "...          ...       ...  ...\n",
       "43794   0.149167  0.000000  0.0\n",
       "43795   0.242083  0.000000  0.0\n",
       "43796   0.540000  0.000000  0.0\n",
       "43797   0.912500  0.000000  0.0\n",
       "43798   1.322083  0.000000  0.0\n",
       "43799   1.620000  0.000000  0.0\n",
       "43800   2.160000  0.000000  0.0\n",
       "43801   2.569583  0.000000  0.0\n",
       "43802   2.942083  0.000000  0.0\n",
       "43803   3.407917  0.000000  0.0\n",
       "43804   3.947917  0.000000  0.0\n",
       "43805   4.581250  0.000000  0.0\n",
       "43806   5.419583  0.000000  0.0\n",
       "43807   5.959583  0.000000  0.0\n",
       "43808   6.257500  0.000000  0.0\n",
       "43809   6.499583  0.000000  0.0\n",
       "43810   6.797500  0.000000  0.0\n",
       "43811   7.095417  0.000000  0.0\n",
       "43812   7.393333  0.000000  0.0\n",
       "43813   7.765833  0.000000  0.0\n",
       "43814   8.175417  0.000000  0.0\n",
       "43815   8.547917  0.000000  0.0\n",
       "43816   8.920417  0.000000  0.0\n",
       "43817   9.218333  0.000000  0.0\n",
       "43818   9.423333  0.000000  0.0\n",
       "43819   9.665417  0.000000  0.0\n",
       "43820   9.907500  0.000000  0.0\n",
       "43821  10.112500  0.000000  0.0\n",
       "43822  10.280000  0.000000  0.0\n",
       "43823  10.410417  0.000000  0.0\n",
       "\n",
       "[43824 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm25_hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our last challenge will be to create an aggregate function and apply it to a select group of columns in our dataframe.\n",
    "\n",
    "Write a function that returns the standard deviation of a column divided by the length of a column minus 1. Since we are using pandas, do not use the `len()` function. One alternative is to use `count()`. Also, use the numpy version of standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sd(x):\n",
    "    '''\n",
    "    Input: A Pandas series of values\n",
    "    Output: the standard deviation divided by the number of elements in the series\n",
    "        \n",
    "    Example:\n",
    "    Input: pd.Series([1,2,3,4])\n",
    "    Output: 0.3726779962\n",
    "    '''\n",
    "    \n",
    "    # your code here\n",
    "    return np.std(x) / (x.count() - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = pm25_hourly.apply(sample_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Iws    4.754929e-05\n",
       "Is     7.229519e-07\n",
       "Ir     1.346183e-06\n",
       "dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
